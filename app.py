# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q_4Eue6Z8mnVVQAZ69ihZOFcsn48mBMe
"""

# app.py

import streamlit as st
import pickle
import re
import string
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences

# 1) T√çTULO Y DESCRIPCI√ìN -------------------------------------------------
st.set_page_config(
    page_title="Detector de Spam",
    page_icon="‚úâÔ∏è",
    layout="centered"
)

st.title("üîé Clasificador de Spam")
st.markdown(
    """
    Esta aplicaci√≥n usa un modelo LSTM previamente entrenado para clasificar
    correos/e-mails como **SPAM** o **HAM** (no spam).
    Ingresa el texto del correo y presiona ‚ÄúClasificar‚Äù.
    """
)

# 2) CARGAR TOKENIZER Y MODELO ---------------------------------------------
@st.cache_resource(show_spinner=False)
def cargar_tokenizer(path="tokenizer_spam.pkl"):
    with open(path, "rb") as f:
        return pickle.load(f)

@st.cache_resource(show_spinner=False)
def cargar_modelo(path="modelo_spam_lstm.h5"):
    return tf.keras.models.load_model(path)

tokenizer = cargar_tokenizer()
model = cargar_modelo()

# 3) FUNCI√ìN DE LIMPIEZA ---------------------------------------------------
def limpiar_texto(texto):
    texto = texto.lower()
    texto = re.sub(r"http\S+", "", texto)            # quitar URLs
    texto = re.sub(r"\d+", "", texto)                 # quitar d√≠gitos
    texto = texto.translate(str.maketrans("", "", string.punctuation))
    texto = texto.strip()
    return texto

# 4) FUNCI√ìN DE PREDICCI√ìN -------------------------------------------------
def predecir_spam(texto_crudo, tokenizer, model, max_len=100):
    """
    Recibe un string (texto_crudo), lo limpia, tokeniza, hace padding y usa el modelo
    para devolver (prob_spam, etiqueta), donde etiqueta es "SPAM" o "HAM".
    """
    # 1) Limpiar
    texto_limpio = limpiar_texto(texto_crudo)

    # 2) Tokenizar ‚Üí secuencia de √≠ndices
    secuencia = tokenizer.texts_to_sequences([texto_limpio])

    # 3) Padding / truncado
    seq_pad = pad_sequences(secuencia, maxlen=max_len, padding="post", truncating="post")

    # 4) Predecir
    prob_spam = model.predict(seq_pad)[0][0]
    etiqueta = "SPAM" if prob_spam > 0.5 else "HAM"

    return prob_spam, etiqueta

# 5) INTERFAZ PRINCIPAL ----------------------------------------------------
st.subheader("Introduce el correo o mensaje para clasificar")
texto_entrada = st.text_area(
    label="‚úâÔ∏è Pega aqu√≠ el texto completo del correo:",
    height=200,
    help="Escribe o pega el contenido del correo que quieras clasificar como spam o ham."
)

if st.button("üöÄ Clasificar"):
    if texto_entrada.strip() == "":
        st.warning("Por favor, ingresa algo de texto antes de clasificar.")
    else:
        with st.spinner("Analizando el mensaje‚Ä¶"):
            prob, etiqueta = predecir_spam(texto_entrada, tokenizer, model)
        st.markdown("---")
        st.write(f"**Probabilidad de SPAM:** `{prob:.3f}`")
        if etiqueta == "SPAM":
            st.error("üè¥ Etiqueta predicha: **SPAM**")
        else:
            st.success("‚úÖ Etiqueta predicha: **HAM**")