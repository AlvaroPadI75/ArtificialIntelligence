# -*- coding: utf-8 -*-
"""Apps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-gLdp1xexHnOm9ILxhzyHVLX-nmyluh1
"""

# app.py

import streamlit as st
import pickle
import re
import string
import numpy as np
import pandas as pd
from PIL import Image

import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences

st.set_page_config(
    page_title="Unified Demo App",
    layout="wide"
)

st.sidebar.title("Navigation")
page = st.sidebar.selectbox(
    "Choose a page:",
    ("Spam Classification", "Pet Breed Classification", "iPhone Price Prediction")
)

# ============================================
# 1) SPAM CLASSIFICATION PAGE
# ============================================

# Cached loader for the spam LSTM model
@st.cache_resource(show_spinner=False)
def load_spam_model():
    model = tf.keras.models.load_model("modelo_spam_lstm.h5")
    return model

# Cached loader for the spam tokenizer
@st.cache_resource(show_spinner=False)
def load_spam_tokenizer():
    with open("tokenizer_spam.pkl", "rb") as f:
        tokenizer = pickle.load(f)
    return tokenizer

# Basic text‚Äêcleaning function (lowercase, remove HTML tags, punctuation, numbers, extra spaces)
def clean_text(text):
    # 1) Lowercase
    text = text.lower()
    # 2) Remove HTML tags
    text = re.sub(r"<.*?>", " ", text)
    # 3) Remove punctuation
    text = text.translate(str.maketrans("", "", string.punctuation))
    # 4) Remove digits
    text = re.sub(r"\d+", " ", text)
    # 5) Remove extra whitespace
    text = re.sub(r"\s+", " ", text).strip()
    return text

def spam_page():
    st.title("üìß Spam vs. Ham Classifier")
    st.markdown(
        """
        Enter an email or message below, and the LSTM model will predict
        whether it is **Spam** or **Not Spam (Ham)**.
        """
    )

    # 1) Load model & tokenizer
    model = load_spam_model()
    tokenizer = load_spam_tokenizer()

    # 2) Determine the max sequence length from the model's input shape
    #    Some models have input_shape = (None, MAXLEN), so index 1 is MAXLEN.
    try:
        maxlen = model.input_shape[1]
    except:
        # If that fails, fall back to a default, e.g., 100
        maxlen = 100

    user_text = st.text_area("Enter the text to classify:", height=200)

    if st.button("Classify"):
        if not user_text.strip():
            st.warning("Please enter some text to classify.")
            return

        # 3) Preprocess
        cleaned = clean_text(user_text)
        seq = tokenizer.texts_to_sequences([cleaned])
        padded = pad_sequences(seq, maxlen=maxlen, padding="post", truncating="post")

        # 4) Predict
        pred_prob = model.predict(padded)[0][0]
        label = "Spam" if pred_prob >= 0.5 else "Not Spam (Ham)"
        st.markdown("---")
        st.write(f"**Prediction:** `{label}`")
        st.write(f"**Spam probability:** `{pred_prob:.3f}`")

# ============================================
# 2) PET BREED CLASSIFICATION PAGE
# ============================================

@st.cache_resource(show_spinner=False)
def load_pet_model():
    model = tf.keras.models.load_model("modelo_pets_mobilenetv2.h5")
    return model

# The 37 class names in the exact order the model was trained on
PET_CLASS_NAMES = [
    "Abyssinian", "American Bobtail", "Bengal", "Birman", "Bombay", "British Shorthair",
    "Egyptian Mau", "Maine Coon", "Persian", "Ragdoll", "Russian Blue", "Siamese",
    "Sphynx", "American Bulldog", "American Pit Bull Terrier", "Basset Hound",
    "Beagle", "Boxer", "Chihuahua", "English Cocker Spaniel", "English Setter",
    "German Shorthaired Pointer", "Great Pyrenees", "Havanese", "Japanese Chin",
    "Keeshond", "Leonberger", "Miniature Pinscher", "Newfoundland", "Pomeranian",
    "Pug", "Saint Bernard", "Samoyed", "Scotch Terrier", "Shiba Inu", "Siberian Husky",
    "Toy Poodle", "Yorkshire Terrier"
]

def preprocess_pet_image(image: Image.Image, target_size=(224, 224)):
    """
    - Convert PIL to RGB
    - Resize to (224, 224)
    - Convert to float32 and normalize to [0, 1]
    - Expand dims to shape (1, 224, 224, 3)
    """
    img = image.convert("RGB")
    img = img.resize(target_size, resample=Image.BICUBIC)
    arr = np.array(img).astype("float32") / 255.0
    arr = np.expand_dims(arr, axis=0)
    return arr

def pet_page():
    st.title("üêæ Pet Breed Classifier (Oxford-IIIT Pet)")
    st.markdown(
        """
        Upload an image of a cat or dog, and the model (MobileNetV2 backbone + custom head)
        will predict the **breed** out of 37 possible categories.
        """
    )

    model = load_pet_model()

    uploaded_file = st.file_uploader(
        "Upload a JPG/PNG image of your pet:", type=["jpg", "jpeg", "png"]
    )

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded image", use_column_width=True)

        x = preprocess_pet_image(image, target_size=(224, 224))
        preds = model.predict(x)            # shape (1, 37)
        prob = float(np.max(preds))         # highest probability
        idx = int(np.argmax(preds))         # class index
        breed = PET_CLASS_NAMES[idx]

        st.markdown("---")
        st.write(f"**Predicted breed:** `{breed}`")
        st.write(f"**Probability:** `{prob:.3f}`")

        # Bar chart of probabilities for all 37 classes
        st.subheader("Probabilities for each class")
        probs_dict = {PET_CLASS_NAMES[i]: float(preds[0][i]) for i in range(len(PET_CLASS_NAMES))}
        st.bar_chart(probs_dict)

# ============================================
# 3) IPHONE PRICE PREDICTION PAGE
# ============================================

@st.cache_resource
def load_regression_model(path="modelo_regresion_iphone.pkl"):
    return joblib.load(path)

pipeline_reg = load_regression_model()

# 2) Extract list of countries that the model expects
#    (we read it from the fitted OneHotEncoder inside the pipeline)
ohe = pipeline_reg.named_steps['preprocessor'].named_transformers_['cat']
country_list = ohe.categories_[0].tolist()

# 3) User inputs
st.subheader("Input Data for Prediction")

col1, col2 = st.columns(2)

with col1:
    tax_input = st.number_input(
        label="Tax (in USD)",
        min_value=0.0,
        value=50.0,
        step=1.0,
        format="%.2f"
    )
    gdp_input = st.number_input(
        label="GDP (total, in USD)",
        min_value=0.0,
        value=2_000_000_000_000.0,  # default: 2 trillion
        step=1e9,
        format="%.0f"
    )

with col2:
    pc_gdp_input = st.number_input(
        label="GDP per Capita (in USD)",
        min_value=0.0,
        value=50_000.0,
        step=1000.0,
        format="%.2f"
    )
    country_input = st.selectbox(
        label="Country",
        options=country_list,
        index=0
    )

# 4) Perform prediction when user clicks button
if st.button("üîÆ Predict iPhone Price"):
    # Build a single-row DataFrame with the same column names the model expects
    X_new = pd.DataFrame([{
        'Tax': tax_input,
        'GDP_num': gdp_input,
        'PC_GDP_num': pc_gdp_input,
        'Country': country_input
    }])

    # Use the pipeline to predict
    predicted_price = pipeline_reg.predict(X_new)[0]

    st.markdown("---")
    st.subheader("Prediction Result")
    st.metric(label="üí∞ Estimated Price (USD)", value=f"{predicted_price:,.2f}")
    st.write(
        "According to the model, the iPhone price is approximately:",
        f"**${predicted_price:,.2f}**"
    )
else:
    st.write("Enter the values above and click **Predict iPhone Price** to see the estimate.")

# ============================================
# MAIN: render the chosen page
# ============================================
if page == "Spam Classification":
    spam_page()
elif page == "Pet Breed Classification":
    pet_page()
elif page == "iPhone Price Prediction":
    iphone_page()
