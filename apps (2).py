# -*- coding: utf-8 -*-
"""Apps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-gLdp1xexHnOm9ILxhzyHVLX-nmyluh1
"""

# app.py

import streamlit as st
import pickle
import re
import string
import numpy as np
import pandas as pd
from PIL import Image

import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences

st.set_page_config(
    page_title="Unified Demo App",
    layout="wide"
)

st.sidebar.title("Navigation")
page = st.sidebar.selectbox(
    "Choose a page:",
    ("Spam Classification", "Pet Breed Classification", "iPhone Price Prediction")
)

# ============================================
# 1) SPAM CLASSIFICATION PAGE
# ============================================

# Cached loader for the spam LSTM model
@st.cache_resource(show_spinner=False)
def load_spam_model():
    model = tf.keras.models.load_model("modelo_spam_lstm.h5")
    return model

# Cached loader for the spam tokenizer
@st.cache_resource(show_spinner=False)
def load_spam_tokenizer():
    with open("tokenizer_spam.pkl", "rb") as f:
        tokenizer = pickle.load(f)
    return tokenizer

# Basic text‚Äêcleaning function (lowercase, remove HTML tags, punctuation, numbers, extra spaces)
def clean_text(text):
    # 1) Lowercase
    text = text.lower()
    # 2) Remove HTML tags
    text = re.sub(r"<.*?>", " ", text)
    # 3) Remove punctuation
    text = text.translate(str.maketrans("", "", string.punctuation))
    # 4) Remove digits
    text = re.sub(r"\d+", " ", text)
    # 5) Remove extra whitespace
    text = re.sub(r"\s+", " ", text).strip()
    return text

def spam_page():
    st.title("üìß Spam vs. Ham Classifier")
    st.markdown(
        """
        Enter an email or message below, and the LSTM model will predict
        whether it is **Spam** or **Not Spam (Ham)**.
        """
    )

    # 1) Load model & tokenizer
    model = load_spam_model()
    tokenizer = load_spam_tokenizer()

    # 2) Determine the max sequence length from the model's input shape
    #    Some models have input_shape = (None, MAXLEN), so index 1 is MAXLEN.
    try:
        maxlen = model.input_shape[1]
    except:
        # If that fails, fall back to a default, e.g., 100
        maxlen = 100

    user_text = st.text_area("Enter the text to classify:", height=200)

    if st.button("Classify"):
        if not user_text.strip():
            st.warning("Please enter some text to classify.")
            return

        # 3) Preprocess
        cleaned = clean_text(user_text)
        seq = tokenizer.texts_to_sequences([cleaned])
        padded = pad_sequences(seq, maxlen=maxlen, padding="post", truncating="post")

        # 4) Predict
        pred_prob = model.predict(padded)[0][0]
        label = "Spam" if pred_prob >= 0.5 else "Not Spam (Ham)"
        st.markdown("---")
        st.write(f"**Prediction:** `{label}`")
        st.write(f"**Spam probability:** `{pred_prob:.3f}`")

# ============================================
# 2) PET BREED CLASSIFICATION PAGE
# ============================================

@st.cache_resource(show_spinner=False)
def load_pet_model():
    model = tf.keras.models.load_model("modelo_pets_mobilenetv2.h5")
    return model

# The 37 class names in the exact order the model was trained on
PET_CLASS_NAMES = [
    "Abyssinian", "American Bobtail", "Bengal", "Birman", "Bombay", "British Shorthair",
    "Egyptian Mau", "Maine Coon", "Persian", "Ragdoll", "Russian Blue", "Siamese",
    "Sphynx", "American Bulldog", "American Pit Bull Terrier", "Basset Hound",
    "Beagle", "Boxer", "Chihuahua", "English Cocker Spaniel", "English Setter",
    "German Shorthaired Pointer", "Great Pyrenees", "Havanese", "Japanese Chin",
    "Keeshond", "Leonberger", "Miniature Pinscher", "Newfoundland", "Pomeranian",
    "Pug", "Saint Bernard", "Samoyed", "Scotch Terrier", "Shiba Inu", "Siberian Husky",
    "Toy Poodle", "Yorkshire Terrier"
]

def preprocess_pet_image(image: Image.Image, target_size=(224, 224)):
    """
    - Convert PIL to RGB
    - Resize to (224, 224)
    - Convert to float32 and normalize to [0, 1]
    - Expand dims to shape (1, 224, 224, 3)
    """
    img = image.convert("RGB")
    img = img.resize(target_size, resample=Image.BICUBIC)
    arr = np.array(img).astype("float32") / 255.0
    arr = np.expand_dims(arr, axis=0)
    return arr

def pet_page():
    st.title("üêæ Pet Breed Classifier (Oxford-IIIT Pet)")
    st.markdown(
        """
        Upload an image of a cat or dog, and the model (MobileNetV2 backbone + custom head)
        will predict the **breed** out of 37 possible categories.
        """
    )

    model = load_pet_model()

    uploaded_file = st.file_uploader(
        "Upload a JPG/PNG image of your pet:", type=["jpg", "jpeg", "png"]
    )

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded image", use_column_width=True)

        x = preprocess_pet_image(image, target_size=(224, 224))
        preds = model.predict(x)            # shape (1, 37)
        prob = float(np.max(preds))         # highest probability
        idx = int(np.argmax(preds))         # class index
        breed = PET_CLASS_NAMES[idx]

        st.markdown("---")
        st.write(f"**Predicted breed:** `{breed}`")
        st.write(f"**Probability:** `{prob:.3f}`")

        # Bar chart of probabilities for all 37 classes
        st.subheader("Probabilities for each class")
        probs_dict = {PET_CLASS_NAMES[i]: float(preds[0][i]) for i in range(len(PET_CLASS_NAMES))}
        st.bar_chart(probs_dict)

# ============================================
# 3) IPHONE PRICE PREDICTION PAGE
# ============================================

@st.cache_resource(show_spinner=False)
def load_iphone_model():
    with open("modelo_regresion_iphone.pkl", "rb") as f:
        pipeline = pickle.load(f)
    return pipeline

def parse_gdp(gdp_str: str):
    """
    Convert a string like "$27.72 trillion" or "$3.5 billion" or "$450,000,000"
    into a numeric value in plain dollars (float).
    """
    if not gdp_str or not isinstance(gdp_str, str):
        return None
    s = gdp_str.replace("$", "").replace(",", "").strip().lower()
    if "trillion" in s:
        val = float(s.replace("trillion", "").strip())
        return val * 1e12
    if "billion" in s:
        val = float(s.replace("billion", "").strip())
        return val * 1e9
    try:
        return float(s)
    except:
        return None

def parse_pc_gdp(pc_str: str):
    """
    Convert a string like "$12,345" or "12345" into a float.
    """
    if not pc_str or not isinstance(pc_str, str):
        return None
    s = pc_str.replace("$", "").replace(",", "").strip()
    try:
        return float(s)
    except:
        return None

def iphone_page():
    st.title("üì± iPhone Price Classification (Expensive vs. Not Expensive)")
    st.markdown(
        """
        Enter the following information for a country, and the model will predict
        whether iPhones in that country are classified as **"Expensive"** (above median)
        or **"Not Expensive"** (below median), based on historical data.
        """
    )

    # 1) Load the regression/classification pipeline
    pipeline = load_iphone_model()

    # 2) User inputs for features
    st.subheader("Enter input features:")
    country = st.text_input("Country name (e.g., United States):", value="United States")
    tax = st.number_input("Tax rate (numeric, e.g. 0.07 for 7%):", min_value=0.0, format="%.4f", value=0.07)
    gdp_str = st.text_input("GDP (e.g. \"$27.72 trillion\" or \"$3.5 billion\"):", value="$1 trillion")
    pcgdp_str = st.text_input("Per Capita GDP (e.g. \"$45,000\" or \"45000\"):", value="$45,000")

    if st.button("Predict Expensiveness"):
        # 3) Parse GDP strings
        gdp_val = parse_gdp(gdp_str)
        pcgdp_val = parse_pc_gdp(pcgdp_str)

        if gdp_val is None or pcgdp_val is None:
            st.error("Could not parse GDP or Per Capita GDP. Please enter in a valid format.")
            return

        # 4) Build a single‚Äêrow DataFrame with the exact columns the pipeline expects
        df_input = pd.DataFrame({
            "Tax": [tax],
            "GDP_num": [gdp_val],
            "PC_GDP_num": [pcgdp_val],
            "Country": [country]
        })

        # 5) Make prediction (this pipeline should output a probability for the ‚ÄúExpensive‚Äù class)
        try:
            prob = pipeline.predict_proba(df_input)[0][1]  # probability of class 1 = ‚ÄúExpensive‚Äù
            label = "Expensive" if prob >= 0.5 else "Not Expensive"
            st.markdown("---")
            st.write(f"**Prediction:** `{label}`")
            st.write(f"**Probability (Expensive):** `{prob:.3f}`")
        except Exception as e:
            st.error(f"Error during prediction: {e}")

# ============================================
# MAIN: render the chosen page
# ============================================
if page == "Spam Classification":
    spam_page()
elif page == "Pet Breed Classification":
    pet_page()
elif page == "iPhone Price Prediction":
    iphone_page()